<HTML>
<HEAD>
  <!-- Created with AOLpress/2.0 -->
  <!-- AP: Created on: 24-Jul-2015 -->
  <!-- AP: Last modified: 29-Jan-2019 -->
  <TITLE>Machine Learning, Linear Regression</TITLE>
</HEAD>
<BODY>
<H1>
  <A HREF="..\ais.htm">Machine Learning</A>
  <A HREF="../../methods.htm">Method</A> Linear Regression
</H1>
<P>
Linear regression is an approach for predicting the relationship between
a single dependent variable y and one or more explanatory variables (or
independent variables) usually called X<SUB>#</SUB>. (To predict which of
several categories y falls in, instead of finding a linear prediction of
y, see <A HREF="logisticregresions.htm">Logistic Regression</A>). This linear
prediction is just like all those algebra problems in the form Y = mX + b
that you did in high school. You can see an example of it on this page:
<BR><A href="https://stackblitz.com/edit/minml?file=index.js">https://stackblitz.com/edit/minml?file=index.js</A>

<P>
The problem with that is it only allows one input (the X) (and it only fits a straight line). Actual Linear Regression supports many inputs. It's still basically Y = mX + b except with more than one X like Y = b +
m<SUB>1</SUB>X<SUB>1</SUB> + m<SUB>2</SUB>X<SUB>2</SUB> ... and to simplify
the math and allow the use of matrix multiplication, we assume an
X<SUB>0</SUB> which is alway set to 1, and change b into m<SUB>0</SUB> and
all the m's into theta or <STRIKE>o</STRIKE>. The result is:
<P>
y = <STRIKE>o</STRIKE><SUB>0</SUB>x<SUB>0</SUB> +
<STRIKE>o</STRIKE><SUB>1</SUB>x<SUB>1</SUB> +
<STRIKE>o</STRIKE><SUB>2</SUB>x<SUB>2</SUB> ...
<P>
which can be expressed via <A HREF="../math/matrix.htm">matrix math </A>as
<STRIKE>O</STRIKE><SUP>T</SUP>X where <STRIKE>O</STRIKE> is a vector of all
the <STRIKE>o</STRIKE>'s e.g. [<STRIKE>o</STRIKE><SUB>0</SUB>,
<STRIKE>o</STRIKE><SUB>1</SUB>, <STRIKE>o</STRIKE><SUB>2</SUB>, ... ] which
used to be all the m's, except <STRIKE>o</STRIKE><SUB>0</SUB> which used
to be the b, and X (note it's uppercase) is a matrix of all the values of
x e.g. &nbsp;[x<SUB>0</SUB> , x<SUB>1</SUB> , x<SUB>2</SUB> , ...] where
x<SUB>0</SUB> is always 1. Note T means Transpose or turn the vector into
a 1x# matrix so it can be multiplied by X. So
<STRIKE>O</STRIKE><SUP>T</SUP>X just takes each element of <STRIKE>O</STRIKE>
and multiplies it times each element of X and adds up the result which is
y.
<P>
<STRIKE>O</STRIKE> becomes the parameters which shape different values of
X into a prediction y. (Note <STRIKE>O</STRIKE> and X are uppercase, y is
lowercase by convention that <STRIKE>O</STRIKE> and X are matrices i.e. arrays
and y is a scalar i.e. a single number)
<P>
The trick is to find a set of values for <STRIKE>O</STRIKE> such that for
every given X, y is a valid prediction. Or rather, given a training set of
values for X, we find values for <STRIKE>O</STRIKE> such that the resulting
values of y are as close as possible to those given in the training set.
Then we can apply new values of X, and hope that y will be predictive. Here
is an example of a linear fit to a set of sample data:
<P>
<IMG SRC="linearfit2data.png" WIDTH="487" HEIGHT="390">
<H4>
  Cost function
</H4>
<P>
In order to find better values for <STRIKE>O</STRIKE>, we need to understand
how wrong our value of y is for ALL the values of X in the training set.
A key point is that there may be values of <STRIKE>O</STRIKE> which work
for ONE value of X but not for others. So when we evaluate our current
<STRIKE>O</STRIKE>, we must sum the error for all the given values (or sets
of values) of our current guess. To do this, we create a cost function which
compares the difference between the desired outcome y and the actual outcome
<STRIKE>O</STRIKE><SUP>T</SUP>X and average that over the number of samples
in the training set, m. (m is used by convention to represent the number
of samples).
<P>
The Mean Squared Error
(MSE)<A HREF="https://en.wikipedia.org/wiki/Mean_squared_error">^</A> function
is commonly used. This is the error squared
(<STRIKE>O</STRIKE><SUP>T</SUP>X - y)<SUP>2</SUP> then the mean of that;
the sum of the error squared, divided by the number of samples. We will actually
compute <I>half</I> the MSE for reasons which will become clear later (hint:
derivative).
<PRE>s = 0;
for (j = 0; j&lt;m; j++) { // m = number of samples, length of y and 2nd dim of X
  for (i = 0; i&lt;p; i++) { // p =number of parameters, length of theta
    hyp = theta[i] * X[j,i]; // transpose done by switching i and j indexes to X
    s += pow(hyp - y[j], 2); // square the error
    } // loop for each parameter
  } // loop for each sample.
return s /(2*m); // divide by the number of samples (mean) times two. 
</PRE>
<P>
This can be optimized with <A HREF="../math/matrix.htm">matrix math</A> systems
such as <A HREF="../../language/octave.htm">Octave</A>. <I>Note that there
are Matrix libraries available for most languages. e.g.
<A HREF="../../language/ccpp/index.htm">C</A>
<A HREF="http://stackoverflow.com/questions/4501322/c-libraries-for-mathematical-matrix-operations">^</A>
<A HREF="https://en.wikipedia.org/wiki/List_of_numerical_libraries#C">^</A>,
<A HREF="../../language/JAVA/SCRIPT/index.htm">JavaScript</A>
<A HREF="https://en.wikipedia.org/wiki/List_of_numerical_libraries#Javascript">^</A>
<A HREF="http://mathjs.org/docs/datatypes/matrices.html">^</A> and others
<A HREF="https://en.wikipedia.org/wiki/List_of_numerical_libraries">^</A></I>
To review: A scalar is a single number, like s, i or j above. A vector is
an array with a single dimension, like theta or y above. A matrix is an array
with multiple dimensions like X above. We don't need loops anymore, because
Octave knows how to multiply matrix, vector, and scalar values automatically...
and quickly.
<PRE>m = length(y); //y is a vector, it's length is the scaler, m
hyp = X*theta; //X is a matrix, theta and hyp are vectors
errs = (hyp - y).^2; //hyp and y match as vectors
cost = sum(errs)/(2*m); //cost is a scalar
</PRE>
<P>
but it turns out cost isn't all that important... what we really need to
calculate is the <I>slope</I> of the cost!
<H4>
  <A NAME="GadientDescent" HREF="gradientdescent.htm" TARGET="_top">
Gradient Descent</A>
</H4>
<P>
In order to change theta to a better value, we can modify it by a small increment
(represented by a or alpha) times the <I>slope</I> of our error. Doing this
again and again will slowly move our prediction over the entire training
set to an optimal line IF the value of alpha is small enough. If alpha is
too large, the new predicted value of theta may overshoot the ideal value
and bounce out of control. Of course, very small values of alpha may convirge
to the ideal parameters very slowly.
<P>
Note that we are computing the derivative of the cost function to find it's
slope so that we know which direction to move and by how much. That's why
we use half the MSE as our cost function: The derivative of
&#189;x<SUP>2</SUP> is x which is easy to calculate. The slope for parameter
<STRIKE>O</STRIKE><SUB>J</SUB> is simply (<STRIKE>O</STRIKE><SUP>T</SUP>X
- y) X, or the actual error (difference not MSE) times X.
<PRE><FONT COLOR="Green"><B>% Basic Linear Regression Gradient Decent with multiple parameters in <A HREF="../../language/octave.htm">Octave</A></B></FONT>
alpha = 0.01; <FONT COLOR="Green">% try larger values 0.01, 0.03, 0.1, 0.3, etc...</FONT> 
m = length(y); <FONT COLOR="Green">% number of training examples</FONT>
p = size(X,2); <FONT COLOR="Green">% number of parameters (second dimension of X)</FONT>

for iter = 1:num_iters
  hyp = X*theta;  <FONT COLOR="Green">%calculate our hypothesis using current parameters</FONT>
  err = (hyp .- y); <FONT COLOR="Green">%find the error between that and the real data</FONT>
  s = ( X' * err )./m; <FONT COLOR="Green">%find the slope of the error.</FONT> <I>(should that be .' instead of '?)</I>
  <FONT COLOR="Green">%Note: This is the derivative of our cost function</FONT>
  theta = theta - alpha .* s; 
  <FONT COLOR="Green">%adjust our parameters by a small distance along that slope.</FONT>
  end
</PRE>
<P>
Given an error curve that smoothly approaches a local minimum, the correction
applied to each theta is decreased as our error slope decreases, even though
alpha is not changed over each run. This helps us quickly converge when the
error is large, but slow down and not overshoot our goal as we approach the
best fit. This nice curve is not always present.
<H3>
  <A HREF="Troubleshooting.htm">Under and Over Fitting</A>
</H3>
<P>
Not all data fits well to a straight line. This is called "underfitting"
or we may say that the algorithm as a "high bias". We can try fitting a quadratic
or even higher order equation. E.g. instead of
<STRIKE>O</STRIKE><SUB>0</SUB> + <STRIKE>O</STRIKE><SUB>1</SUB>x, we might
use <STRIKE>O</STRIKE><SUB>0</SUB> + <STRIKE>O</STRIKE><SUB>1</SUB>x +
<STRIKE>O</STRIKE><SUB>2</SUB>x<SUP>2</SUP>. But, if we choose an equation
of too high an order, then we might "overfit" or have an algorithm with "high
variance", which would fit any function and isn't representing the function
behind this data. Overfitting can therefore result in predictions for new
examples which are not accurate even though it exactly predicts the data
in the training set. The training data may well have some noise, or outliers,
which are not actually representative of the true function.
<H3>
  <A HREF="Regularization.htm">Regularization</A>
</H3>
<P>
To keep the system from <A HREF="Troubleshooting.htm">over fitting</A>, and
instead provide a more generalized fit, we can add the sum values of
<STRIKE>O</STRIKE> (the theta parameters) to the cost and slope of the error.
This makes the system find the <I>smallest</I> values for <STRIKE>O</STRIKE>
that still fit the data. We are saying "even if our training data makes it
look like this one parameter (or a few parameters) are really important,
don't raise it's theta to much... try to find a fit that uses more of the
parameters". We can scale the degree of generalization by multiplying that
sum times a value we call "Lambda".
<P>
To implement this, we adjust the value of S in our calculation above as follows:
<PRE>reg = lambda .* [0;theta(2:end)] ./ m ;
S = S + reg;
</PRE>
<P>
Notice we do NOT include <STRIKE>o</STRIKE><SUB>0</SUB> aka theta(1) (because
<A HREF="../../language/octave.htm">Octave</A> indexes from 1) in the
calculation, instead replacing it with 0, using the code
<TT>[0;theta(2:end)]</TT> which builds a new matrix with 0 as the first element,
and then the 2nd and following elements of the original theta. Remember that
theta(1) is basically the b in y=mx+b; it is the offset of the line vertically.
If we penalized the system for having higher values of theta(1), it wouldn't
want to find a very nice line that fits the data, when those data points
are all high above (or far below) the axis.
<H3>
  <A NAME="FeatureNormalization">Feature Normalization</A>
</H3>
<P>
Re-centering and scaling also helps the gradient descent converge faster.
(and could avoid the need to exclude theta(1) during regularization)
<PRE>mu = mean(X); <FONT COLOR="Green">%mean of training set</FONT>
sigma = std(X); <FONT COLOR="Green">%standard deviation of training set.</FONT>
X = X - mu; <FONT COLOR="Green">%normalize all data to center around the mean</FONT>
X = X ./ sigma; <FONT COLOR="Green">% and scale by the deviation.</FONT> 
</PRE>
<P>
Of course, you must also normalize the new data when making a prediction
using the resulting parameters and de-normalize the resulting prediction.
<H2>
  Faster Methods:
</H2>
<P>
But there are better (and more complex) means of adjusting the theta (parameter)
values to minumize cost.
<P>
<B><BIG>Stochastic or Mini-Batch Gradient Descent:</BIG></B> When working
with a <A HREF="BigData.htm">very large number of data points</A>, other
types of Gradient Descent such as
<A HREF="BigData.htm#StochasticGradientDescent">Stochastic or Mini-Batch</A>
can be much faster.
<P>
<B><BIG>Find Minimum Function: </BIG>f<TT>minunc( @[cost, slope] = cost(theta,
X, y), theta, options )</TT></B>
<P>
fminuc is a common and powerful method. The fminunc function expects a reference
to a function which will return cost and (optionally) slope / gradient values
for a given set of parameters, training data, and training answers. It starts
from an initial set of parameters and there are some options which can be
set, such as the maximum number of iterations.
<P>
Here is a complete learning function in
<A HREF="../../language/octave.htm">Octave</A> using fminunc:
<PRE>function [J, S] = costSlope(theta, X, y, lambda)
<FONT COLOR="Green">%return cost (J) and slope (S) given training data (X, y), current theta, and lambda</FONT>
  m = length(y);
  hyp = X*theta; 
  <FONT COLOR="Green">%make a guess based on our training data times our current parameters.</FONT> 
  costs = (hyp - y).^2; <FONT COLOR="Green">%costs with MSE (note .^ and NOT ^)</FONT>
  J = sum(costs(:))/(2*m); <FONT COLOR="Green">%mean cost. (:) required for higher dimensions</FONT>
  reg = lambda * sum(theta(2:end).^2) / (2*m); <FONT COLOR="Green">%Regularize. Replace theta(1) with 0</FONT>
  J = J + reg; <FONT COLOR="Green">%add in the regularization</FONT> 
  err = (hyp .- y); <FONT COLOR="Green">%actual error.</FONT> <BR>  <FONT COLOR="Green">%Note this happens to be the derivative of our cost function.</FONT>
  S = (X' * err)./m; <FONT COLOR="Green">%slope of the error</FONT> 
  reg = lambda .* [0;theta(2:end)] ./ m; <FONT COLOR="Green">%Also regularize the slope</FONT>
  S = S + reg; <FONT COLOR="Green">%add in the regularization</FONT>
  end

options = optimset('GradObj', 'on', 'MaxIter', 400);
[theta, cost] = fminunc(@(t)(costSlope(t, X, y, lambda)), initial_theta, options);
</PRE>
<P>
For more about the @(t) () syntax see
<A HREF="../../language/octave.htm#AnonymousFunctions">Octave: Anonymous
Functions</A>
<P>
<B><BIG>Find Minimum Quadratic and Cubic</BIG></B>: <TT><B>[theta, fX, i]
= <A HREF="fmincg.htm">fmincg</A>(</B>@(t)(Cost(theta, X, y, lambda))<B>,
guess, options)</B></TT>
<P>
This works similarly to fminunc, but is more efficient when we are dealing
with large number of parameters.
<P>
Also:
<UL>
  <LI>
    <A NAME="42231.9645949074" HREF="SupportVectorMachine.htm" TARGET="_top">Support
    Vector Machine</A> (when used with no kernel, as a "Linear SVM")
</UL>
<P>
See also:
<UL>
  <LI>
    <A TITLE="68.111.139.51" NAME="42882.8862615741" HREF="https://xkcd.com/1838/"
	TARGET="_top">https://xkcd.com/1838/</A> <!-- 42882.8862615741 EOR -->
  <LI>
    <A HREF="https://jsfiddle.net/pjLxsw3e/15/">https://jsfiddle.net/pjLxsw3e/15/</A>
    A practical example in JavaScript which can be run and edited online. This
    is only a starting point and has many issues.<!-- 42702.7739930556 EOR -->
  <LI>
    <A HREF="http://joonku.com/project/machine_learning">http://joonku.com/project/machine_learning</A> <A HREF="http://web.archive.org/web/20180420000639/joonku.com/project/machine_learning">Cached</A>
    A very nice demo in the browser which is interactive. It readjusts as you
    click to add data points.
  <LI>
    <A HREF="http://www.statisticsviews.com/details/feature/5722691/Getting-to-the-Bottom-of-Regression-with-Gradient-Descent.html">http://www.statisticsviews.com/details/feature/5722691/Getting-to-the-Bottom-of-Regression-with-Gradient-Descent.html</A>
  <LI>
    <A HREF="http://distill.pub/2017/momentum/">http://distill.pub/2017/momentum/</A>
    Adding Momentum (or "acceleration") to gradient descent. Instead of
    <STRIKE>O</STRIKE><SUP>i+1</SUP> = <STRIKE>O</STRIKE><SUP>i</SUP> - a V
    <I>f</I>(<STRIKE>O</STRIKE><SUP>i</SUP>) we do z<SUP>i+1</SUP> = B *
    z<SUP>k</SUP> + V <I>f</I>(<STRIKE>O</STRIKE><SUP>i</SUP>) and then
    <STRIKE>O</STRIKE><SUP>i+1</SUP> = <STRIKE>O</STRIKE><SUP>i</SUP> - a *
    z<SUP>i+1</SUP> (V is used here as a poor replacement for the
    <A HREF="https://en.wikipedia.org/wiki/Del">Del operator</A>)
</UL>
<P>



<P>Interested:
<UL>
   <LI>

</UL>

<P>Comments:
<UL>
   <LI>

</UL>

<P><A TITLE="JMN-EFP-786" NAME="45066.824375">
<iframe width="560" height="315" src="https://www.youtube.com/embed/my3lsV-VQjs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></A>

<!-- 45066.824375 EOR -->
</BODY></HTML>