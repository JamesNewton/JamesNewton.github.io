<html>

  <body>
 <P>Structured light vision techniques greatly simplify the process of triangulating the position of a point in space. 
   Using structured light techniques, one can do realtime navigation without lots of horsepower. 
   This is because one is able to project a beam with known coordinates. 
   This provides information about at least one aspect of the geometry in front of the camera, 
   so the triangulation equations are much easier and less computationally expensive.</P>

  <P>Structured light techniques are far superior to sonar for range and shape measurements in quality and potentially cheaper. 
    They are able to map out the region in front of the camera quickly and accurately. The angular resolution of structured light systems is quite good.
  They are also better than IR sensors because they are far more reliable, higher resolution, and easier to debug because they can be seen.
  </P>
  <P>The basic idea with structured light vision is to project a light beam of known geometry onto a scene and then use a video camera to observe how it is distorted by objects. 
    Using simple geometric formulas, one can reconstruct the shape of those objects. </P>
    
<P>There are several optical attachments to laser diodes which produce wide planes of laser light without any moving parts. 
  Additionally, one does not have to use a visible laser to perform the scan. 
  Most cameras will detect infrared laser beams quite well (some cameras are more sensitive to infrared light).</P>

    <h2>Basic idea</h2>
<P>Here we see a self-scanning laser diode projecting a beam onto the region in front of it; above is the camera.</P>
<img src="https://github.com/user-attachments/assets/bed5a360-4e0c-4042-8196-958c8d85bb5b">
<p>This arrangement would produce the following images:</p>
<img src="https://github.com/user-attachments/assets/47940609-fa21-4390-8936-0ea71c3e7148">
<img src="https://github.com/user-attachments/assets/bb4d4a8f-591f-4410-aa60-98d5052b3715">
<img src="https://github.com/user-attachments/assets/95f94e3b-2931-404b-9ebe-bc61d281bf2d">
<p>The first image is what the camera sees with the laser on. 
  The second image is what the camera sees with the laser off. 
  The third image is the mathematical difference of the two. 
  By subtracting the first two images, only the difference between them is left: the laser projection. 
  Finally, one may want to filter the difference image so that the scanned beam appears no thicker than one pixel. 
  This will aid in map building.
</p>    
<h2>Scene Geometry and Range Calculation</h2>
    <p>
Now that we have a bitmap image of the laser scan on the objects (and knowing the geometry of the scanner and laser), 
      we can reconstruct the geometry of the scene.

Examining a simplified form of the laser projection below, where <ul>
      <li>h is height of the camera above the laser light plane, </li>
      <li>r is the distance between the camera and the object, </li>
      <li>y is the y-coordinate of the projection of the laser light on the object as seen on the camera bitmap and </li>
      <li>f is the focal length of the camera.</li>
  </ul>
    </p>
    <img src="https://github.com/user-attachments/assets/18023e6e-73d6-4d0f-819a-d0637ae7464a">
    <P>Using simlar triangles, we see that: y / f = h / ( r + f ). Solving for 'r' we arrive at: r = ( f * h ) / y - f
    </P>
Since we know f and h, we can determine the range, r, as a function of y.

<h2>Software Implementation</h2>
    <p>
We now merely have to scan the difference bitmap and calculate the range of any pixels that result from the laser projection.</p>
<pre>
     For y = 1 to Bitmap.YMax
          For x = -Bitmap.XMax to Bitmap.XMax
               If Bitmap.Pixel(x,y) != 0 then
                    ry = f*h/y - f
                    rx = x * (f+ry)/f
                    rz = -h

                   { Now do something with the knowledge        }
                   { that a pixel maps to a particular position }
                   { relative to the camera. Perhaps convert    }
                   { to absolute coordinates and build a map    }
               end if
          next x
     next y
</pre>

    <h2>Reality</h2>
    <p>Of course the issue with this is it assumes a perfect set of pictures, with no motion between the frames.
    In fact, a mobile robot will be moving (it's right there in the name) and the two images will be shifted slightly.
    But this really doesn't cause as much of an issue as one might think. 
    And in fact, the shift is valuable on it's own. </p>
    <p>The difference between the frames will be larger given relative motion of the pixels caused by motion of the robot or objects around the robot.
    Objects moving around the robot SHOULD be seen!
    We want the robot to react to things that might run into it or interact with it.
    </p>
    <p>Motion caused by the robot falls into two areas: Rotational shifts and Perspective shifts.</p>
    <

    
  </body>
</html>
